{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe25137",
   "metadata": {},
   "source": [
    "# Q.1 Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19c16cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "['Welcome to Wikipedia', \"From today's featured article\", 'Did you know\\xa0...', 'In the news', 'On this day', \"Today's featured picture\", 'Other areas of Wikipedia', \"Wikipedia's sister projects\", 'Wikipedia languages']\n"
     ]
    }
   ],
   "source": [
    "#importing Libraries for \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Sending Request to website\n",
    "url=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "# Downloading Page Source Code\n",
    "soup= BeautifulSoup(url.content)\n",
    "\n",
    "# to capture main heading\n",
    "heading_1=soup.find('h1',class_=\"firstHeading mw-first-heading\").text\n",
    "print (heading_1)\n",
    "\n",
    "\n",
    "# To scrap all headings from the page\n",
    "#creating Empty list\n",
    "news_feeds=[]\n",
    "#appending the headings inti news_feeds \n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    news_feeds.append(i.text)\n",
    "\n",
    "#printing the news_feed\n",
    "print(news_feeds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a8542",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f9bc45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name with year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.       The Shawshank Redemption (1994)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.       The Godfather (1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.       The Dark Knight (2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.       The Godfather Part II (1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.       12 Angry Men (1957)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.       Citizen Kane (1941)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.       M - Eine Stadt sucht einen Mörder (1...</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.       Lawrence of Arabia (1962)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.       North by Northwest (1959)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.       Vertigo (1958)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Movie Name with year  Ratings\n",
       "0            1.       The Shawshank Redemption (1994)    9.2 \n",
       "1                       2.       The Godfather (1972)    9.2 \n",
       "2                     3.       The Dark Knight (2008)    9.0 \n",
       "3               4.       The Godfather Part II (1974)    9.0 \n",
       "4                        5.       12 Angry Men (1957)    9.0 \n",
       "..                                                ...     ...\n",
       "95                      96.       Citizen Kane (1941)    8.3 \n",
       "96  97.       M - Eine Stadt sucht einen Mörder (1...    8.3 \n",
       "97                98.       Lawrence of Arabia (1962)    8.3 \n",
       "98                99.       North by Northwest (1959)    8.2 \n",
       "99                          100.       Vertigo (1958)    8.2 \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Sending Request to website\n",
    "url=requests.get('https://www.imdb.com/chart/top/')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "\n",
    "#scraping all 100 movie names\n",
    "\n",
    "title=soup.find_all('td',class_=\"titleColumn\")\n",
    "\n",
    "title\n",
    "\n",
    "movie_name=[]\n",
    "for i in title:\n",
    "    i=i.get_text().replace('\\n',\" \").strip(\" \")\n",
    "    movie_name.append(i)\n",
    "    \n",
    "movie_name\n",
    "\n",
    "#Scraping its rating\n",
    "\n",
    "ratings=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "\n",
    "ratings\n",
    "\n",
    "movie_rating=[]\n",
    "for i in ratings:\n",
    "    movie_rating.append(i.get_text().replace('\\n',\" \"))\n",
    "    \n",
    "movie_rating\n",
    "\n",
    "# Making DataFrame\n",
    "df=pd.DataFrame({'Movie Name with year ':movie_name,'Ratings':movie_rating})\n",
    "\n",
    "dataset=df.drop(df.index[100:], axis=0)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784cbbb",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9436e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name with year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.       Ramayana: The Legend of Prince Rama (...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.       Rocketry: The Nambi Effect (2022)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.       Golmaal (1979)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.       777 Charlie (2022)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.       Nayakan (1987)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.       Kaakkaa Muttai (2014)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.       Ustad Hotel (2012)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.       Theeran Adhigaaram Ondru (2017)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.       Angoor (1982)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.       Rang De Basanti (2006)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Movie Name with year  Ratings\n",
       "0   1.       Ramayana: The Legend of Prince Rama (...    8.5 \n",
       "1          2.       Rocketry: The Nambi Effect (2022)    8.4 \n",
       "2                             3.       Golmaal (1979)    8.4 \n",
       "3                         4.       777 Charlie (2022)    8.4 \n",
       "4                             5.       Nayakan (1987)    8.4 \n",
       "..                                                ...     ...\n",
       "95                    96.       Kaakkaa Muttai (2014)    8.0 \n",
       "96                       97.       Ustad Hotel (2012)    8.0 \n",
       "97          98.       Theeran Adhigaaram Ondru (2017)    8.0 \n",
       "98                            99.       Angoor (1982)    8.0 \n",
       "99                  100.       Rang De Basanti (2006)    8.0 \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Sending Request to website\n",
    "url=requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "\n",
    "#scraping all 100 movie names\n",
    "\n",
    "title=soup.find_all('td',class_=\"titleColumn\")\n",
    "\n",
    "title\n",
    "\n",
    "movie_name=[]\n",
    "for i in title:\n",
    "    i=i.get_text().replace('\\n',\" \").strip(\" \")\n",
    "    movie_name.append(i)\n",
    "    \n",
    "movie_name\n",
    "\n",
    "#Scraping its rating\n",
    "\n",
    "ratings=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "\n",
    "ratings\n",
    "\n",
    "movie_rating=[]\n",
    "for i in ratings:\n",
    "    movie_rating.append(i.get_text().replace('\\n',\" \"))\n",
    "    \n",
    "movie_rating\n",
    "\n",
    "# Making DataFrame\n",
    "df=pd.DataFrame({'Movie Name with year ':movie_name,'Ratings':movie_rating})\n",
    "\n",
    "dataset=df.drop(df.index[100:], axis=0)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5a337",
   "metadata": {},
   "source": [
    "# 4) Write a python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21ccf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Ram Nath Kovind (birth - 1945) Term of Office: 25 July, 2017 to 25 July, 2022  https://ramnathkovind.nic.in',\n",
       " 'Shri Pranab Mukherjee (1935-2020) Term of Office: 25 July, 2012 to 25 July, 2017  http://pranabmukherjee.nic.in',\n",
       " 'Smt Pratibha Devisingh Patil (birth - 1934) Term of Office: 25 July, 2007 to 25 July, 2012  http://pratibhapatil.nic.in',\n",
       " 'DR. A.P.J. Abdul Kalam (1931-2015) Term of Office: 25 July, 2002 to 25 July, 2007  http://abdulkalam.nic.in',\n",
       " 'Shri K. R. Narayanan (1920 - 2005) Term of Office: 25 July, 1997 to 25 July, 2002',\n",
       " 'Dr Shankar Dayal Sharma (1918-1999) Term of Office: 25 July, 1992 to 25 July, 1997',\n",
       " 'Shri R Venkataraman (1910-2009) Term of Office: 25 July, 1987 to 25 July, 1992',\n",
       " 'Giani Zail Singh (1916-1994) Term of Office: 25 July, 1982 to 25 July, 1987',\n",
       " 'Shri Neelam Sanjiva Reddy (1913-1996) Term of Office: 25 July, 1977 to 25 July, 1982',\n",
       " 'Dr. Fakhruddin Ali Ahmed (1905-1977) Term of Office: 24 August, 1974 to 11 February, 1977',\n",
       " 'Shri Varahagiri Venkata Giri (1894-1980) Term of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " 'Dr. Zakir Husain (1897-1969) Term of Office: 13 May, 1967 to 3 May, 1969',\n",
       " 'Dr. Sarvepalli Radhakrishnan (1888-1975) Term of Office: 13 May, 1962 to 13 May, 1967',\n",
       " 'Dr. Rajendra Prasad (1884-1963)  Term of Office: 26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#scraping names of Presidents and term of office\n",
    "\n",
    "President_name=soup.find_all('div',class_=\"presidentListing\")\n",
    "\n",
    "# making a list name and tenure\n",
    "Presidents=[]\n",
    "\n",
    "for i in President_name:\n",
    "    Presidents.append(i.get_text().replace('\\n',\" \").strip(\" \"))\n",
    "Presidents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e1229",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f4208c1",
   "metadata": {},
   "source": [
    "# Q. 5 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70738878",
   "metadata": {},
   "source": [
    "Q.5) a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b02db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Top_10_ODI TEAMS</th>\n",
       "      <th>Matches_top10</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>23</td>\n",
       "      <td>2,670</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,400</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Australia</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>35</td>\n",
       "      <td>3,866</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>30</td>\n",
       "      <td>2,677</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>19</td>\n",
       "      <td>1,380</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position Top_10_ODI TEAMS Matches_top10 Points Ratings\n",
       "0        1      New Zealand            23  2,670     116\n",
       "1        2          England            30  3,400     113\n",
       "2        3        Australia            32  3,572     112\n",
       "3        4            India            35  3,866     110\n",
       "4        5         Pakistan            22  2,354     107\n",
       "5        6     South Africa            24  2,392     100\n",
       "6        7       Bangladesh            30  2,753      92\n",
       "7        8        Sri Lanka            30  2,677      89\n",
       "8        9      Afghanistan            19  1,380      73\n",
       "9       10      West Indies            41  2,902      71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#Scraping position\n",
    "\n",
    "first_pos=soup.find_all('td', class_=\"rankings-block__banner--pos\")\n",
    "next_pos=soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "\n",
    "next_pos\n",
    "\n",
    "Position=[]\n",
    "\n",
    "for i in first_pos:\n",
    "    Position.append(i.text)\n",
    "for i in next_pos:\n",
    "    Position.append(i.text)\n",
    "    \n",
    "Position\n",
    "\n",
    "\n",
    "#scraping top 10  ODI teams \n",
    "\n",
    "first_place=soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "teams=[]\n",
    "for i in first_place:\n",
    "    teams.append(i.text)\n",
    "    \n",
    "teams\n",
    "\n",
    "#scraping matches\n",
    "\n",
    "first=soup.find_all('td', class_=\"rankings-block__banner--matches\")\n",
    "next_match=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "j=next_match[0::2]\n",
    "\n",
    "matches=[]\n",
    "\n",
    "for i in first:\n",
    "    matches.append(i.text)\n",
    "for i in j:\n",
    "    matches.append(i.text)\n",
    "    \n",
    "matches\n",
    "\n",
    "#scraping points\n",
    "\n",
    "first_p=soup.find_all('td', class_=\"rankings-block__banner--points\")\n",
    "next_p=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "points=next_p[1::2]\n",
    "\n",
    "Point=[]\n",
    "\n",
    "for i in first_p:\n",
    "    Point.append(i.text)\n",
    "for i in points:\n",
    "    Point.append(i.text)\n",
    "    \n",
    "Point\n",
    "\n",
    "#scraping rating\n",
    "\n",
    "first_r=soup.find_all('td', class_=\"rankings-block__banner--rating u-text-right\")\n",
    "next_r=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "next_r\n",
    "\n",
    "Rating=[]\n",
    "\n",
    "for i in first_r:\n",
    "    Rating.append(i.text.replace('\\n', \" \").strip())\n",
    "for i in next_r:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Rating\n",
    "\n",
    "# Making DataFrame\n",
    "\n",
    "ODI_Data_mens=pd.DataFrame({'Position':Position,'Top_10_ODI TEAMS':teams,'Matches_top10':matches,'Points':Point, 'Ratings':Rating})\n",
    "\n",
    "ODI_Data_mens=ODI_Data_mens.drop(ODI_Data_mens.index[10:], axis=0)\n",
    "\n",
    "ODI_Data_mens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd08fb",
   "metadata": {},
   "source": [
    " Q.5 b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce6483a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Name of Player</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position         Name of Player Country Ratings\n",
       "0        1             Babar Azam     PAK     890\n",
       "1        2            Imam-ul-Haq     PAK     779\n",
       "2        3  Rassie van der Dussen      SA     766\n",
       "3        4        Quinton de Kock      SA     759\n",
       "4        5           David Warner     AUS     747\n",
       "5        6            Steve Smith     AUS     719\n",
       "6        7         Jonny Bairstow     ENG     710\n",
       "7        8            Virat Kohli     IND     707\n",
       "8        9           Rohit Sharma     IND     704\n",
       "9       10        Kane Williamson      NZ     701"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#Scraping position of player\n",
    "\n",
    "first_pos=soup.find('span', class_=\"rankings-block__pos-number\")\n",
    "next_pos=soup.find_all('span',class_='rankings-table__pos-number')\n",
    "\n",
    "next_pos\n",
    "\n",
    "Position=[]\n",
    "\n",
    "for i in first_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "for i in next_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "    \n",
    "Position=Position[0:10]\n",
    "\n",
    "Position\n",
    "\n",
    "\n",
    "#scraping name of batsmen\n",
    "\n",
    "first_name=soup.find_all('div', class_=\"rankings-block__banner--name\")[0]\n",
    "next_name=soup.find_all('td',class_='table-body__cell name')\n",
    "\n",
    "next_name\n",
    "\n",
    "names=[]\n",
    "\n",
    "for i in first_name:\n",
    "    names.append(i.text)\n",
    "for i in next_name:\n",
    "    names.append(i.text.strip())\n",
    "    \n",
    "names=names[0:10]\n",
    "names\n",
    "\n",
    "#scraping name of Country\n",
    "\n",
    "first_country=soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "next_country=soup.find_all('td',class_='table-body__cell nationality-logo')\n",
    "\n",
    "first_country\n",
    "\n",
    "Country_name=[]\n",
    "\n",
    "for i in first_country:\n",
    "    Country_name.append(i.text.strip().replace('\\n','').split()[0])\n",
    "    \n",
    "Country_name=Country_name[0]\n",
    "Country_name\n",
    "\n",
    "Name_of_country=[]\n",
    "Name_of_country.append(Country_name)\n",
    "Name_of_country\n",
    "\n",
    "for i in next_country:\n",
    "    Name_of_country.append(i.text.replace('\\n',''))\n",
    "\n",
    "Name_of_country=Name_of_country[0:10]\n",
    "Name_of_country\n",
    "\n",
    "#scraping Rating\n",
    "\n",
    "first_rating=soup.find('div', class_=\"rankings-block__banner--rating\")\n",
    "next_rating=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "Ratings=[]\n",
    "\n",
    "for i in first_rating:\n",
    "    Ratings.append(i.text)\n",
    "for i in next_rating:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "Ratings=Ratings[0:10]\n",
    "\n",
    "Ratings\n",
    "\n",
    "Top_10_Batsmen=pd.DataFrame({'Position':Position,'Name of Player':names,'Country':Name_of_country, 'Ratings':Ratings})\n",
    "\n",
    "\n",
    "Top_10_Batsmen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a675886",
   "metadata": {},
   "source": [
    "Q.5 c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d98279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Name of Player</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position     Name of Player Country Ratings\n",
       "0        1        Trent Boult      NZ     760\n",
       "1        2     Josh Hazlewood     AUS     727\n",
       "2        3     Mitchell Starc     AUS     665\n",
       "3        4     Shaheen Afridi     PAK     661\n",
       "4        5         Matt Henry      NZ     656\n",
       "5        6         Adam Zampa     AUS     655\n",
       "6        7       Mehedi Hasan     BAN     655\n",
       "7        8   Mujeeb Ur Rahman     AFG     650\n",
       "8        9  Mustafizur Rahman     BAN     640\n",
       "9       10        Rashid Khan     AFG     635"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#Scraping position of player\n",
    "\n",
    "first_pos=soup.find('span', class_=\"rankings-block__pos-number\")\n",
    "next_pos=soup.find_all('span',class_='rankings-table__pos-number')\n",
    "\n",
    "next_pos\n",
    "\n",
    "Position=[]\n",
    "\n",
    "for i in first_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "for i in next_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "    \n",
    "Position=Position[0:10]\n",
    "\n",
    "Position\n",
    "\n",
    "\n",
    "#scraping name of batsmen\n",
    "\n",
    "first_name=soup.find_all('div', class_=\"rankings-block__banner--name\")[1]\n",
    "next_name=soup.find_all('td',class_='table-body__cell name')\n",
    "\n",
    "next_name\n",
    "\n",
    "names=[]\n",
    "\n",
    "for i in first_name:\n",
    "    names.append(i.text)\n",
    "for i in next_name:\n",
    "    names.append(i.text.strip())\n",
    "    \n",
    "names\n",
    "Bowler=[]\n",
    "Bowler.append(names[0])\n",
    "\n",
    "for i in names[10:19]:\n",
    "    Bowler.append(i)\n",
    "    \n",
    "Bowler\n",
    "\n",
    "#scraping name of Country\n",
    "\n",
    "first_country=soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "next_country=soup.find_all('td',class_='table-body__cell nationality-logo')\n",
    "\n",
    "first_country\n",
    "\n",
    "Country_name=[]\n",
    "\n",
    "for i in first_country:\n",
    "    Country_name.append(i.text.strip().replace('\\n','').split()[0])\n",
    "\n",
    "Country_name\n",
    "\n",
    "Country_name=Country_name[1]\n",
    "Country_name\n",
    "\n",
    "Name_of_country=[]\n",
    "Name_of_country.append(Country_name)\n",
    "Name_of_country\n",
    "\n",
    "for i in next_country:\n",
    "    Name_of_country.append(i.get_text().replace('\\n',''))\n",
    "\n",
    "state=[]\n",
    "state.append(Name_of_country[0])\n",
    "for i in Name_of_country[10:19]:\n",
    "    state.append(i)\n",
    "    \n",
    "state\n",
    "\n",
    "#scraping Rating\n",
    "\n",
    "first_rat=soup.find_all('div', class_=\"rankings-block__banner--rating\")[1]\n",
    "next_rat=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "Ratings_bowl=[]\n",
    "\n",
    "first_rat\n",
    "\n",
    "for i in first_rat:\n",
    "    Ratings_bowl.append(i.text)\n",
    "\n",
    "for i in next_rat:\n",
    "    Ratings_bowl.append(i.text)\n",
    "    \n",
    "Bowler_rating=[]\n",
    "\n",
    "Bowler_rating.append(Ratings_bowl[0])\n",
    "Bowler_rating\n",
    "for i in Ratings_bowl[10:19]:\n",
    "    Bowler_rating.append(i)\n",
    "    \n",
    "Bowler_rating\n",
    "\n",
    "# Preparing DateFrame\n",
    "\n",
    "Top_10_Bowler=pd.DataFrame({'Position':Position,'Name of Player':Bowler,'Country':state, 'Ratings':Bowler_rating})\n",
    "\n",
    "\n",
    "Top_10_Bowler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64d2d3",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f727dcb",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f669a05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Top_10_ODI TEAMS</th>\n",
       "      <th>Matches_top10</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>3,061</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>England</td>\n",
       "      <td>25</td>\n",
       "      <td>2,904</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>24</td>\n",
       "      <td>2,425</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>24</td>\n",
       "      <td>2,334</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>932</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>1,519</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position Top_10_ODI TEAMS Matches_top10 Points Ratings\n",
       "0        1        Australia            18  3,061     170\n",
       "1        2     South Africa            26  3,098     119\n",
       "2        3          England            25  2,904     116\n",
       "3        4            India            27  2,820     104\n",
       "4        5      New Zealand            24  2,425     101\n",
       "5        6      West Indies            24  2,334      97\n",
       "6        7       Bangladesh            12    932      78\n",
       "7        8         Thailand             8    572      72\n",
       "8        9         Pakistan            24  1,519      63\n",
       "9       10        Sri Lanka             8    353      44"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#Scraping position\n",
    "\n",
    "first_pos=soup.find_all('td', class_=\"rankings-block__banner--pos\")\n",
    "next_pos=soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "\n",
    "next_pos\n",
    "\n",
    "Position=[]\n",
    "\n",
    "for i in first_pos:\n",
    "    Position.append(i.text)\n",
    "for i in next_pos:\n",
    "    Position.append(i.text)\n",
    "    \n",
    "Position=Position[0:10]\n",
    "Position\n",
    "\n",
    "\n",
    "#scraping top 10  ODI teams \n",
    "\n",
    "first_place=soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "teams=[]\n",
    "for i in first_place:\n",
    "    teams.append(i.text)\n",
    "    \n",
    "teams=teams[0:10]\n",
    "teams\n",
    "\n",
    "#scraping matches\n",
    "\n",
    "first=soup.find_all('td', class_=\"rankings-block__banner--matches\")\n",
    "next_match=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "j=next_match[0::2]\n",
    "\n",
    "matches=[]\n",
    "\n",
    "for i in first:\n",
    "    matches.append(i.text)\n",
    "for i in j:\n",
    "    matches.append(i.text)\n",
    "    \n",
    "matches=matches[0:10]\n",
    "matches\n",
    "\n",
    "#scraping points\n",
    "\n",
    "first_p=soup.find_all('td', class_=\"rankings-block__banner--points\")\n",
    "next_p=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "points=next_p[1::2]\n",
    "\n",
    "Point=[]\n",
    "\n",
    "for i in first_p:\n",
    "    Point.append(i.text)\n",
    "for i in points:\n",
    "    Point.append(i.text)\n",
    "    \n",
    "Point=Point[0:10]\n",
    "Point\n",
    "\n",
    "#scraping rating\n",
    "\n",
    "first_r=soup.find_all('td', class_=\"rankings-block__banner--rating u-text-right\")\n",
    "next_r=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "next_r\n",
    "\n",
    "Rating=[]\n",
    "\n",
    "for i in first_r:\n",
    "    Rating.append(i.text.replace('\\n', \" \").strip())\n",
    "for i in next_r:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Rating=Rating[0:10]\n",
    "Rating\n",
    "\n",
    "# Making DataFrame\n",
    "\n",
    "ODI_Data_womens=pd.DataFrame({'Position':Position,'Top_10_ODI TEAMS':teams,'Matches_top10':matches,'Points':Point, 'Ratings':Rating})\n",
    "\n",
    "ODI_Data_womens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299368e7",
   "metadata": {},
   "source": [
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e75f9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Name of Player</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position       Name of Player Country Ratings\n",
       "0        1         Alyssa Healy     AUS     785\n",
       "1        2          Beth Mooney     AUS     749\n",
       "2        3      Laura Wolvaardt      SA     732\n",
       "3        4       Natalie Sciver     ENG     725\n",
       "4        5     Harmanpreet Kaur     IND     716\n",
       "5        6      Smriti Mandhana     IND     714\n",
       "6        7          Meg Lanning     AUS     710\n",
       "7        8       Rachael Haynes     AUS     701\n",
       "8        9    Amy Satterthwaite      NZ     661\n",
       "9       10  Chamari Athapaththu      SL     655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#Scraping position of player\n",
    "\n",
    "first_pos=soup.find('span', class_=\"rankings-block__pos-number\")\n",
    "next_pos=soup.find_all('span',class_='rankings-table__pos-number')\n",
    "\n",
    "next_pos\n",
    "\n",
    "Position=[]\n",
    "\n",
    "for i in first_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "for i in next_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "    \n",
    "Position=Position[0:10]\n",
    "\n",
    "Position\n",
    "\n",
    "#scraping name of batwomen\n",
    "\n",
    "first_name=soup.find_all('div', class_=\"rankings-block__banner--name\")[0]\n",
    "next_name=soup.find_all('td',class_='table-body__cell name')\n",
    "\n",
    "next_name\n",
    "\n",
    "names=[]\n",
    "\n",
    "for i in first_name:\n",
    "    names.append(i.text)\n",
    "for i in next_name:\n",
    "    names.append(i.text.strip())\n",
    "    \n",
    "names=names[0:10]\n",
    "names\n",
    "\n",
    "#scraping name of Country\n",
    "\n",
    "first_country=soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "next_country=soup.find_all('td',class_='table-body__cell nationality-logo')\n",
    "\n",
    "first_country\n",
    "\n",
    "Country_name=[]\n",
    "\n",
    "for i in first_country:\n",
    "    Country_name.append(i.text.strip().replace('\\n','').split()[0])\n",
    "    \n",
    "Country_name=Country_name[0]\n",
    "Country_name\n",
    "\n",
    "Name_of_country=[]\n",
    "Name_of_country.append(Country_name)\n",
    "Name_of_country\n",
    "\n",
    "for i in next_country:\n",
    "    Name_of_country.append(i.text.replace('\\n',''))\n",
    "\n",
    "Name_of_country=Name_of_country[0:10]\n",
    "Name_of_country\n",
    "\n",
    "#scraping Rating\n",
    "\n",
    "first_rating=soup.find('div', class_=\"rankings-block__banner--rating\")\n",
    "next_rating=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "Ratings=[]\n",
    "\n",
    "for i in first_rating:\n",
    "    Ratings.append(i.text)\n",
    "for i in next_rating:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "Ratings=Ratings[0:10]\n",
    "\n",
    "Ratings\n",
    "\n",
    "Top_10_Batswomen=pd.DataFrame({'Position':Position,'Name of Player':names,'Country':Name_of_country, 'Ratings':Ratings})\n",
    "\n",
    "\n",
    "Top_10_Batswomen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f900667",
   "metadata": {},
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee5bf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Name of Player</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position       Name of Player Country Ratings\n",
       "0        1    Sophie Ecclestone     ENG     739\n",
       "1        2        Jess Jonassen     AUS     725\n",
       "2        3         Megan Schutt     AUS     722\n",
       "3        4       Shabnim Ismail      SA     722\n",
       "4        5       Jhulan Goswami     IND     698\n",
       "5        6      Hayley Matthews      WI     671\n",
       "6        7           Kate Cross     ENG     657\n",
       "7        8       Ayabonga Khaka      SA     634\n",
       "8        9  Rajeshwari Gayakwad     IND     617\n",
       "9       10       Marizanne Kapp      SA     598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#Scraping position of player\n",
    "\n",
    "first_pos=soup.find('span', class_=\"rankings-block__pos-number\")\n",
    "next_pos=soup.find_all('span',class_='rankings-table__pos-number')\n",
    "\n",
    "next_pos\n",
    "\n",
    "Position=[]\n",
    "\n",
    "for i in first_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "for i in next_pos:\n",
    "    Position.append(i.text.replace('\\n',' ').strip())\n",
    "    \n",
    "Position=Position[0:10]\n",
    "\n",
    "Position\n",
    "\n",
    "\n",
    "#scraping name of batsmen\n",
    "\n",
    "first_name=soup.find_all('div', class_=\"rankings-block__banner--name\")[1]\n",
    "next_name=soup.find_all('td',class_='table-body__cell name')\n",
    "\n",
    "next_name\n",
    "\n",
    "names=[]\n",
    "\n",
    "for i in first_name:\n",
    "    names.append(i.text)\n",
    "for i in next_name:\n",
    "    names.append(i.text.strip())\n",
    "    \n",
    "names\n",
    "Bowler=[]\n",
    "Bowler.append(names[0])\n",
    "\n",
    "for i in names[10:19]:\n",
    "    Bowler.append(i)\n",
    "    \n",
    "Bowler\n",
    "\n",
    "#scraping name of Country\n",
    "\n",
    "first_country=soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "next_country=soup.find_all('td',class_='table-body__cell nationality-logo')\n",
    "\n",
    "first_country\n",
    "\n",
    "Country_name=[]\n",
    "\n",
    "for i in first_country:\n",
    "    Country_name.append(i.text.strip().replace('\\n','').split()[0])\n",
    "\n",
    "Country_name\n",
    "\n",
    "Country_name=Country_name[1]\n",
    "Country_name\n",
    "\n",
    "Name_of_country=[]\n",
    "Name_of_country.append(Country_name)\n",
    "Name_of_country\n",
    "\n",
    "for i in next_country:\n",
    "    Name_of_country.append(i.get_text().replace('\\n',''))\n",
    "\n",
    "state=[]\n",
    "state.append(Name_of_country[0])\n",
    "for i in Name_of_country[10:19]:\n",
    "    state.append(i)\n",
    "    \n",
    "state\n",
    "\n",
    "#scraping Rating\n",
    "\n",
    "first_rat=soup.find_all('div', class_=\"rankings-block__banner--rating\")[1]\n",
    "next_rat=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "Ratings_bowl=[]\n",
    "\n",
    "first_rat\n",
    "\n",
    "for i in first_rat:\n",
    "    Ratings_bowl.append(i.text)\n",
    "\n",
    "for i in next_rat:\n",
    "    Ratings_bowl.append(i.text)\n",
    "    \n",
    "Bowler_rating=[]\n",
    "\n",
    "Bowler_rating.append(Ratings_bowl[0])\n",
    "Bowler_rating\n",
    "for i in Ratings_bowl[10:19]:\n",
    "    Bowler_rating.append(i)\n",
    "    \n",
    "Bowler_rating\n",
    "\n",
    "# Preparing DateFrame\n",
    "\n",
    "Top_10_Bowler=pd.DataFrame({'Position':Position,'Name of Player':Bowler,'Country':state, 'Ratings':Bowler_rating})\n",
    "\n",
    "\n",
    "Top_10_Bowler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7374b0b",
   "metadata": {},
   "source": [
    "# Q. 7 Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "#i) Headline\n",
    "#ii) Time\n",
    "3iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31bacc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latest News</th>\n",
       "      <th>Time</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPEC+ agrees to stick to its existing policy o...</td>\n",
       "      <td>8 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/opec-meeting-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parking lots are becoming as important as cars...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/parking-lots-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon's cloud unit faces cost-sensitive custo...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/aws-faces-cost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don’t overlook this health warning on your dec...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/dont-overlook-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How electric air taxis could shake up the airl...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/how-electric-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I raised 2 successful CEOs and a doctor. Here'...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/i-raised-2-suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delta pilots would get more than 30% in pay ra...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/delta-pilots-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Men participate less in 401(k) plans than wome...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/men-participat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The best U.S. states to raise a family if you ...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/best-states-ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Susan Cain: This Bob Dylan-inspired phrase can...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/bestselling-au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The difference between this comeback and the m...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/the-difference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Goldman says buy these five stocks for the lon...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/goldman-says-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Celsius users with crypto collateral stuck tur...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/celsius-users-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cramer's lightning round: Let Extreme Networks...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jim Cramer says these 3 apparel stocks benefit...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/jim-cramer-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cramer’s week ahead: Markets need a strong job...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pro Picks: Watch all of Friday's big stock cal...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>There is 'enormous opportunity' in REITs, says...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/reits-offer-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Biden administration will end monkeypox public...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/biden-administ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Expect more choppiness ahead after a week of m...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/expect-more-ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GM, LG investing $275 million to expand Tennes...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/gm-lg-investin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>These beat-up tech stocks have potential, ‘Hal...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/big-tech-stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The Fed's path to a 'Goldilocks' economy just ...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/the-feds-path-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3 things crypto investors need to know in post...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/three-things-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Biden condemns antisemitism as Ye praises Hitl...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/biden-condemns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Georgia man arrested for shooting boy campaign...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/georgia-electi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What to watch in the markets in the week ahead</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/markets-lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The biggest tax changes to know before filing ...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/the-biggest-ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'This is a crisis.' Why more workers need acce...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/why-more-worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Carnival’s Princess Cruises will return to Jap...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/carnivals-prin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Latest News              Time  \\\n",
       "0   OPEC+ agrees to stick to its existing policy o...         8 Min Ago   \n",
       "1   Parking lots are becoming as important as cars...      21 Hours Ago   \n",
       "2   Amazon's cloud unit faces cost-sensitive custo...      22 Hours Ago   \n",
       "3   Don’t overlook this health warning on your dec...      22 Hours Ago   \n",
       "4   How electric air taxis could shake up the airl...      22 Hours Ago   \n",
       "5   I raised 2 successful CEOs and a doctor. Here'...      22 Hours Ago   \n",
       "6   Delta pilots would get more than 30% in pay ra...      22 Hours Ago   \n",
       "7   Men participate less in 401(k) plans than wome...      23 Hours Ago   \n",
       "8   The best U.S. states to raise a family if you ...      23 Hours Ago   \n",
       "9   Susan Cain: This Bob Dylan-inspired phrase can...      23 Hours Ago   \n",
       "10  The difference between this comeback and the m...      23 Hours Ago   \n",
       "11  Goldman says buy these five stocks for the lon...      23 Hours Ago   \n",
       "12  Celsius users with crypto collateral stuck tur...  December 3, 2022   \n",
       "13  Cramer's lightning round: Let Extreme Networks...  December 2, 2022   \n",
       "14  Jim Cramer says these 3 apparel stocks benefit...  December 2, 2022   \n",
       "15  Cramer’s week ahead: Markets need a strong job...  December 2, 2022   \n",
       "16  Pro Picks: Watch all of Friday's big stock cal...  December 2, 2022   \n",
       "17  There is 'enormous opportunity' in REITs, says...  December 2, 2022   \n",
       "18  Biden administration will end monkeypox public...  December 2, 2022   \n",
       "19  Expect more choppiness ahead after a week of m...  December 2, 2022   \n",
       "20  GM, LG investing $275 million to expand Tennes...  December 2, 2022   \n",
       "21  These beat-up tech stocks have potential, ‘Hal...  December 2, 2022   \n",
       "22  The Fed's path to a 'Goldilocks' economy just ...  December 2, 2022   \n",
       "23  3 things crypto investors need to know in post...  December 2, 2022   \n",
       "24  Biden condemns antisemitism as Ye praises Hitl...  December 2, 2022   \n",
       "25  Georgia man arrested for shooting boy campaign...  December 2, 2022   \n",
       "26     What to watch in the markets in the week ahead  December 2, 2022   \n",
       "27  The biggest tax changes to know before filing ...  December 2, 2022   \n",
       "28  'This is a crisis.' Why more workers need acce...  December 2, 2022   \n",
       "29  Carnival’s Princess Cruises will return to Jap...  December 2, 2022   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2022/12/04/opec-meeting-o...  \n",
       "1   https://www.cnbc.com/2022/12/03/parking-lots-b...  \n",
       "2   https://www.cnbc.com/2022/12/03/aws-faces-cost...  \n",
       "3   https://www.cnbc.com/2022/12/03/dont-overlook-...  \n",
       "4   https://www.cnbc.com/2022/12/03/how-electric-a...  \n",
       "5   https://www.cnbc.com/2022/12/03/i-raised-2-suc...  \n",
       "6   https://www.cnbc.com/2022/12/03/delta-pilots-w...  \n",
       "7   https://www.cnbc.com/2022/12/03/men-participat...  \n",
       "8   https://www.cnbc.com/2022/12/03/best-states-ra...  \n",
       "9   https://www.cnbc.com/2022/12/03/bestselling-au...  \n",
       "10  https://www.cnbc.com/2022/12/03/the-difference...  \n",
       "11  https://www.cnbc.com/2022/12/03/goldman-says-b...  \n",
       "12  https://www.cnbc.com/2022/12/03/celsius-users-...  \n",
       "13  https://www.cnbc.com/2022/12/02/cramers-lightn...  \n",
       "14  https://www.cnbc.com/2022/12/02/jim-cramer-say...  \n",
       "15  https://www.cnbc.com/2022/12/02/cramers-week-a...  \n",
       "16  https://www.cnbc.com/2022/12/02/pro-picks-watc...  \n",
       "17  https://www.cnbc.com/2022/12/02/reits-offer-en...  \n",
       "18  https://www.cnbc.com/2022/12/02/biden-administ...  \n",
       "19  https://www.cnbc.com/2022/12/02/expect-more-ch...  \n",
       "20  https://www.cnbc.com/2022/12/02/gm-lg-investin...  \n",
       "21  https://www.cnbc.com/2022/12/02/big-tech-stock...  \n",
       "22  https://www.cnbc.com/2022/12/02/the-feds-path-...  \n",
       "23  https://www.cnbc.com/2022/12/02/three-things-c...  \n",
       "24  https://www.cnbc.com/2022/12/02/biden-condemns...  \n",
       "25  https://www.cnbc.com/2022/12/02/georgia-electi...  \n",
       "26  https://www.cnbc.com/2022/12/02/markets-lookin...  \n",
       "27  https://www.cnbc.com/2022/12/02/the-biggest-ta...  \n",
       "28  https://www.cnbc.com/2022/12/02/why-more-worke...  \n",
       "29  https://www.cnbc.com/2022/12/02/carnivals-prin...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "#scraping latest news with Headline, time step and news link\n",
    "\n",
    "#scraping news feed\n",
    "\n",
    "Headlines=soup.find_all('a', class_=\"LatestNews-headline\")\n",
    "\n",
    "News_feed=[]\n",
    "\n",
    "for i in Headlines:\n",
    "    News_feed.append(i.text)\n",
    "    \n",
    "News_feed\n",
    "\n",
    "#scraping timestep\n",
    "\n",
    "timestep=soup.find_all('time', class_=\"LatestNews-timestamp\")\n",
    "\n",
    "time=[]\n",
    "\n",
    "for i in timestep:\n",
    "    time.append(i.text)\n",
    "    \n",
    "time\n",
    "\n",
    "#scraping NEWS LINK\n",
    "\n",
    "link=soup.find_all('a', class_=\"LatestNews-headline\")\n",
    "\n",
    "News_link=[]\n",
    "\n",
    "for i in link:\n",
    "    News_link.append(i.get('href'))\n",
    "    \n",
    "News_link\n",
    "\n",
    "# Making Data Frame\n",
    "NewsData=pd.DataFrame({'Latest News':News_feed, 'Time': time, 'Link':News_link })\n",
    "\n",
    "NewsData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709d16b",
   "metadata": {},
   "source": [
    "# Q.8 Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75debd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Research Article</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Date of Publication</th>\n",
       "      <th>Paper Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Research Article  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors Date of Publication  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...        October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more        October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni         October 2015   \n",
       "3                                 Boden, Margaret A.          August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more           June 2017   \n",
       "5                                        Miller, Tim        February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more          April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...       February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...         August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more          March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...       February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.         October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more         August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more          April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat        December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant          August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders       September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...           June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.        December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge       September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...            May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...        January 2014   \n",
       "22                      Kohavi, Ron, John, George H.        December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...        October 2021   \n",
       "24                                   Ying, Mingsheng        February 2010   \n",
       "\n",
       "                                           Paper Link  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "# Scraping Paper title\n",
    "\n",
    "paper=soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\")\n",
    "\n",
    "Paper_title=[]\n",
    "\n",
    "for i in paper:\n",
    "    Paper_title.append(i.text)\n",
    "    \n",
    "\n",
    "Paper_title\n",
    "\n",
    "# Scraping Paper Authors\n",
    "\n",
    "Authors=soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\")\n",
    "\n",
    "Paper_Authors=[]\n",
    "\n",
    "for i in Authors:\n",
    "    Paper_Authors.append(i.text)\n",
    "    \n",
    "\n",
    "Paper_Authors\n",
    "\n",
    "# Scraping Paper publication date\n",
    "\n",
    "date=soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\")\n",
    "\n",
    "publication_date=[]\n",
    "\n",
    "for i in date:\n",
    "    publication_date.append(i.text)\n",
    "    \n",
    "publication_date\n",
    "\n",
    "# Scraping Paper url\n",
    "\n",
    "paper_link=soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\")\n",
    "\n",
    "Paper_Link=[]\n",
    "\n",
    "for i in paper_link:\n",
    "    Paper_Link.append(i.get('href'))\n",
    "    \n",
    "Paper_Link\n",
    "\n",
    "# Making Data Frame\n",
    "PaperData=pd.DataFrame({'Research Article':Paper_title, 'Authors': Paper_Authors, 'Date of Publication':publication_date,'Paper Link':Paper_Link})\n",
    "\n",
    "PaperData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3315e28",
   "metadata": {},
   "source": [
    "# Q.9 Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08a07460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Restaurant cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Resto Rating</th>\n",
       "      <th>Image Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant Name             Restaurant cuisine  \\\n",
       "0                   Castle Barbeque          Chinese, North Indian   \n",
       "1                   Jungle Jamboree   North Indian, Asian, Italian   \n",
       "2                   Castle Barbeque          Chinese, North Indian   \n",
       "3                        Cafe Knosh           Italian, Continental   \n",
       "4              The Barbeque Company          North Indian, Chinese   \n",
       "5                       India Grill          North Indian, Italian   \n",
       "6                    Delhi Barbeque                   North Indian   \n",
       "7  The Monarch - Bar Be Que Village                   North Indian   \n",
       "8                 Indian Grill Room          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Resto Rating  \\\n",
       "0                     Connaught Place, Central Delhi          4.1   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi          3.9   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi          3.9   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...          4.3   \n",
       "4                 Gardens Galleria,Sector 38A, Noida            4   \n",
       "5               Hilton Garden Inn,Saket, South Delhi          3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi          3.6   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad          3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon          4.3   \n",
       "\n",
       "                                           Image Url  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "# Scraping Restaurant name\n",
    "\n",
    "Resto=soup.find_all('a',class_=\"restnt-name ellipsis\")\n",
    "\n",
    "Name=[]\n",
    "\n",
    "for i in Resto:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "Name\n",
    "\n",
    "# Scraping cuisine\n",
    "\n",
    "cuisine=soup.find_all('span',class_=\"double-line-ellipsis\")\n",
    "\n",
    "Type=[]\n",
    "\n",
    "for i in cuisine:\n",
    "    Type.append(i.text.split('|')[1])\n",
    "    \n",
    "Type\n",
    "\n",
    "# Scraping Location\n",
    "\n",
    "add=soup.find_all('div',class_=\"restnt-loc ellipsis\")\n",
    "\n",
    "Location=[]\n",
    "\n",
    "for i in add:\n",
    "    Location.append(i.text)\n",
    "    \n",
    "Location\n",
    "\n",
    "# Scraping Location\n",
    "\n",
    "stars=soup.find_all('div',class_=\"restnt-rating rating-4\")\n",
    "\n",
    "Rating=[]\n",
    "\n",
    "for i in stars:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Rating\n",
    "\n",
    "# Scraping image-url\n",
    "\n",
    "image=soup.find_all('img',class_=\"no-img\")\n",
    "\n",
    "URL=[]\n",
    "\n",
    "for i in image:\n",
    "    URL.append(i.get('data-src'))\n",
    "    \n",
    "URL\n",
    "\n",
    "# Making Data Frame\n",
    "RestoData=pd.DataFrame({'Restaurant Name':Name, 'Restaurant cuisine': Type, 'Location':Location,'Resto Rating':Rating, 'Image Url':URL })\n",
    "\n",
    "RestoData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01d114",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "i) Rank\n",
    "ii) Publication\n",
    "iii) h5-index\n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b2b6e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank of Publication</th>\n",
       "      <th>Publication Name</th>\n",
       "      <th>h5_median</th>\n",
       "      <th>h5-index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>667</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>780</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>614</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>627</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>635</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>233</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>209</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>201</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>228</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>212</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank of Publication                                   Publication Name  \\\n",
       "0                   1.                                             Nature   \n",
       "1                   2.                The New England Journal of Medicine   \n",
       "2                   3.                                            Science   \n",
       "3                   4.  IEEE/CVF Conference on Computer Vision and Pat...   \n",
       "4                   5.                                         The Lancet   \n",
       "..                 ...                                                ...   \n",
       "95                 96.                       Journal of Business Research   \n",
       "96                 97.                                   Molecular Cancer   \n",
       "97                 98.                                            Sensors   \n",
       "98                 99.                              Nature Climate Change   \n",
       "99                100.                    IEEE Internet of Things Journal   \n",
       "\n",
       "   h5_median h5-index  \n",
       "0        667      444  \n",
       "1        780      667  \n",
       "2        614      432  \n",
       "3        627      780  \n",
       "4        635      401  \n",
       "..       ...      ...  \n",
       "95       233      296  \n",
       "96       209      173  \n",
       "97       201      228  \n",
       "98       228      173  \n",
       "99       212      217  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Request to website\n",
    "url=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "\n",
    "#Downloding source code\n",
    "soup=BeautifulSoup(url.content)\n",
    "\n",
    "# Scraping Rank\n",
    "\n",
    "Rank=soup.find_all('td',class_=\"gsc_mvt_p\")\n",
    "\n",
    "Publication_rank=[]\n",
    "\n",
    "for i in Rank:\n",
    "    Publication_rank.append(i.text)\n",
    "    \n",
    "Publication_rank\n",
    "\n",
    "# Scraping Publication\n",
    "\n",
    "publication=soup.find_all('td',class_=\"gsc_mvt_t\")\n",
    "\n",
    "Publication_name=[]\n",
    "\n",
    "for i in publication:\n",
    "    Publication_name.append(i.text)\n",
    "    \n",
    "Publication_name\n",
    "\n",
    "# Scraping h5_index\n",
    "\n",
    "index=soup.find_all('td',class_=\"gsc_mvt_n\")\n",
    "\n",
    "h5_index=[]\n",
    "\n",
    "for i in index:\n",
    "    h5_index.append(i.text)\n",
    "    \n",
    "h5_index\n",
    "\n",
    "h5=pd.DataFrame({'h5_index':h5_index})\n",
    "\n",
    "h5=h5.drop(h5.index[100:], axis=0)\n",
    "\n",
    "\n",
    "# Scraping h5_median\n",
    "\n",
    "median=soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\")\n",
    "\n",
    "h5_median=[]\n",
    "\n",
    "for i in median:\n",
    "    h5_median.append(i.text)\n",
    "    \n",
    "h5_median\n",
    "\n",
    "# Making Data Frame\n",
    "Data=pd.DataFrame({'Rank of Publication':Publication_rank, 'Publication Name': Publication_name,'h5_median':h5_median })\n",
    "\n",
    "Data.insert(3, \"newcol\", h5['h5_index'])\n",
    "\n",
    "Data=Data.rename({'newcol':'h5-index'}, axis=1)\n",
    "\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2862b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa76d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
